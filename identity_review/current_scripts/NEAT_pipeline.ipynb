{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline to create the NEAT model.\n",
    "\n",
    "There will be a collection of features to use in the analysis\n",
    "- Total number of suspicious transaction based on the random forest model\n",
    "- Total in / out going value of a transaction (this would be two different features)\n",
    "- Total number of 0 seconds between transactions (could be evidence for structuring)\n",
    "- Average number of daily transactions (another feature for structuring)\n",
    "- need to do more research to find other features for the basis of model\n",
    "\n",
    "Things I don't see working:\n",
    "- Number of unique wallets money is sent to\n",
    "\n",
    "need to look into saving the normalizer as well when the data is passed through because the machine has no idea what it's reading when passing in unnormalized data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "\n",
    "import pandas as pd\n",
    "from NEAT_get_transaction import get_transaction_history\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Index(['index', 'to_address', 'from_address', 'value', 'gas',\n",
      "       'block_timestamp', 'time_b/w_trans', 'day', 'month', 'hour',\n",
      "       'type_of_trans'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "api_key = '5M47SltcWwM6LG4DjNisTcSdNs175YsOUePfgmVKqYSAOFxPRaPaD2VRF4H4V4SH'\n",
    "address = '0x098b716b8aaf21512996dc57eb0615e2383e2f96'\n",
    "\n",
    "current_history = get_transaction_history(api_key, address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most updated random forest model\n",
    "def get_current_rf(path):\n",
    "    try:\n",
    "        list_files = os.listdir(path)\n",
    "        files = [file for file in list_files if file != '.DS_Store']\n",
    "        files.sort()\n",
    "        model = pickle.load(open(path + files[-1], 'rb'))\n",
    "        return model\n",
    "    except FileNotFoundError as fe:\n",
    "        print(str(fe) + \"\\nReturning Object of Class None.\")\n",
    "        return None\n",
    "    except pickle.UnpicklingError as pe:\n",
    "        print(\"Error when unpickling file: \" + str(pe) + \".\\nReturning Object of Class None.\")\n",
    "        return None\n",
    "    \n",
    "def get_current_normalizer(path):\n",
    "    try:\n",
    "        list_files = os.listdir(path)\n",
    "        files = [file for file in list_files if file != '.DS_Store']\n",
    "        files.sort()\n",
    "        model = pickle.load(open(path + files[-1], 'rb'))\n",
    "        return model\n",
    "    except FileNotFoundError as fe:\n",
    "        print(str(fe) + \"\\nReturning Object of Class None.\")\n",
    "        return None\n",
    "    except pickle.UnpicklingError as pe:\n",
    "        print(\"Error when unpickling file: \" + str(pe) + \".\\nReturning Object of Class None.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "path = \"/Users/matthewschultz/Big_Data_Lab/identity_review/iteration_rand_forest/\"\n",
    "model = get_current_rf(path)\n",
    "\n",
    "scalar = get_current_normalizer(\"/Users/matthewschultz/Big_Data_Lab/identity_review/normalizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_normalized = scalar.transform(current_history[['value', 'time_b/w_trans']])\n",
    "\n",
    "not_normalized = current_history[['day', 'hour', 'type_of_trans']].to_numpy()\n",
    "\n",
    "combined = np.concatenate((to_be_normalized, not_normalized), axis = 1)\n",
    "\n",
    "\n",
    "normalized = pd.DataFrame(combined)\n",
    "normalized = normalized.rename(columns = {\n",
    "    0: 'value',\n",
    "    1: 'time_b/w_trans',\n",
    "    2: 'day',\n",
    "    3: 'hour',\n",
    "    4: 'type_of_trans',\n",
    "    })\n",
    "\n",
    "\n",
    "predicted = []\n",
    "for index, row in normalized.iterrows():\n",
    "    predict = model.predict(row[['value', 'time_b/w_trans', 'day', 'hour','type_of_trans']].to_numpy().reshape(1, -1))\n",
    "    predicted.append(predict)\n",
    "\n",
    "normalized[\"malicious\"] = predicted\n",
    "\n",
    "num_of_mal_trans = (normalized.loc[normalized['malicious'] == 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.021000601482196\n"
     ]
    }
   ],
   "source": [
    "value_out = current_history.loc[current_history['type_of_trans'] == 1]\n",
    "value_out = sum(value_out['value'])\n",
    "value_in = current_history.loc[current_history['type_of_trans'] == 0]\n",
    "value_in = sum(value_in['value'])\n",
    "\n",
    "print(value_out / value_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_trans_per_day(df):\n",
    "    months = [*set(df['month'])]\n",
    "    days = [*set(df['day'])]\n",
    "    day_by_day = [len(df.loc[df['block_timestamp'].str.contains('{}-{}'.format(month, day))]) for month in months for day in days]\n",
    "    day_by_day = [val for val in day_by_day if val > 0]\n",
    "    return sum(day_by_day) / len(day_by_day)\n",
    "    \n",
    "    \n",
    "\n",
    "avg_trans = get_avg_trans_per_day(current_history)\n",
    "\n",
    "num_of_zero = len(current_history.loc[current_history['time_b/w_trans'] == 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14 (main, Sep  6 2022, 23:28:57) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
